{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import sys\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import importlib\n",
    "\n",
    "# import outsiders\n",
    "sys.path.append('../pre_processing_and_recover_network')\n",
    "import data_preprocessing\n",
    "importlib.reload(data_preprocessing)\n",
    "\n",
    "sys.path.append('../pytorch_model')\n",
    "import ECG\n",
    "importlib.reload(ECG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_data = data_preprocessing.load_data(os.path.join(\"../pre_processing_and_recover_network/swell_dataset/\",\"swell_dict.npy\"))\n",
    "swell_data = data_preprocessing.swell_prepare_for_10fold(swell_data)\n",
    "before=copy.copy(swell_data)\n",
    "#fix the range of the labels to init from value of zero\n",
    "swell_data[:,1:4]-=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For spliting subjests for Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot len is  14595\n",
      "trin len is  13135.5\n",
      "test len is  1459.5\n",
      "train obj:\n",
      "test obj:\n",
      "{2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0} 12567\n",
      "{1.0, 18.0, 25.0} 2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "def train_test_indexes_var2(ratio, objects):\n",
    "    # Split objects into train and test sets\n",
    "    num_test = int(len(set(objects)))-int(len(set(objects)) * ratio)\n",
    "    obj_list = list(set(objects))\n",
    "    random.shuffle(obj_list)\n",
    "    test_objs = obj_list[:num_test]\n",
    "    train_objs = obj_list[num_test:]\n",
    "\n",
    "    train_idxs = []\n",
    "    test_idxs = []\n",
    "\n",
    "    # Assign each object's samples to the appropriate set\n",
    "    for obj in train_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        train_idxs.extend(obj_idxs)\n",
    "\n",
    "    for obj in test_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        test_idxs.extend(obj_idxs)\n",
    "\n",
    "    # Shuffle the final train and test sets\n",
    "    random.shuffle(train_idxs)\n",
    "    random.shuffle(test_idxs)\n",
    "\n",
    "    return (train_idxs), (test_idxs)\n",
    "# check train_test_indexes_var2()\n",
    "# not for each runnig acieve exaclty 9:1 train:test\n",
    "ratio = 0.9\n",
    "objects=swell_data[:,0]\n",
    "print(\"tot len is \", len(objects))\n",
    "print(\"trin len is \",ratio*len(objects))\n",
    "print(\"test len is \",len(objects)-ratio*len(objects))\n",
    "i=train_test_indexes_var2(ratio, objects)\n",
    "\n",
    "\n",
    "print(\"train obj:\")\n",
    "tr=[]\n",
    "for j in i[0]:\n",
    "  tr.append(objects[int(j)])\n",
    "tr_u=set(tr)\n",
    "\n",
    "print(\"test obj:\")\n",
    "te=[]\n",
    "for j in i[1]:\n",
    "  te.append(objects[int(j)])\n",
    "te_u=set(te)\n",
    "\n",
    "print(tr_u,len(tr))\n",
    "print(te_u,len(te))\n",
    "splits=i\n",
    "np.save(\"./splits_B\",splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr=[]\n",
    "y_tr=[]\n",
    "for i in splits[0]:\n",
    "    x_tr.append(swell_data[i,4:])\n",
    "    y_tr.append(swell_data[i,:4])\n",
    "x_train=np.array(x_tr)\n",
    "y_train=np.array(y_tr)\n",
    "\n",
    "x_te=[]\n",
    "y_te=[]\n",
    "for i in splits[1]:\n",
    "    x_te.append(swell_data[i,4:])\n",
    "    y_te.append(swell_data[i,:4])\n",
    "x_test=np.array(x_te)\n",
    "y_test=np.array(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "(x_train).shape\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float().unsqueeze(1)\n",
    "y_train = torch.tensor(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float().unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).long()\n",
    "tensor_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "tensor_dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "train_loader = DataLoader(tensor_dataset, batch_size=128) # for debug set num_workers=0\n",
    "test_loader = DataLoader(tensor_dataset_test,batch_size=128) # for debug set num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model =ECG.EmotionRec()\n",
    "# training\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 100)\n",
    "torch.save(model.state_dict(), './model_light_100_B.pt')\n",
    "trainer.fit(model, train_loader,test_loader)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 150)\n",
    "torch.save(model.state_dict(), './model_light_250_B.pt')\n",
    "trainer.fit(model, train_loader,test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For randomal splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_indexes(len_data, train_ratio):\n",
    "    indexes = list(range(len_data))\n",
    "    random.shuffle(indexes)\n",
    "    train_size = int(len_data * train_ratio)\n",
    "    train_indexes = indexes[:train_size]\n",
    "    test_indexes = indexes[train_size:]\n",
    "    return (train_indexes, test_indexes)\n",
    "\n",
    "splits=split_data_indexes(swell_data.shape[0],0.9)\n",
    "np.save(\"./splits_A\",splits)\n",
    "x_tr=[]\n",
    "y_tr=[]\n",
    "for i in splits[0]:\n",
    "    x_tr.append(swell_data[i,4:])\n",
    "    y_tr.append(swell_data[i,:4])\n",
    "x_train=np.array(x_tr)\n",
    "y_train=np.array(y_tr)\n",
    "\n",
    "x_te=[]\n",
    "y_te=[]\n",
    "for i in splits[1]:\n",
    "    x_te.append(swell_data[i,4:])\n",
    "    y_te.append(swell_data[i,:4])\n",
    "x_test=np.array(x_te)\n",
    "y_test=np.array(y_te)\n",
    "\n",
    "(x_train).shape\n",
    "print(type(x_train))\n",
    "\n",
    "x_train = torch.from_numpy(x_train).float().unsqueeze(1)\n",
    "y_train = torch.tensor(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float().unsqueeze(1)\n",
    "y_test = torch.tensor(y_test).long()\n",
    "tensor_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "tensor_dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "train_loader = DataLoader(tensor_dataset, batch_size=128) # for debug set num_workers=0\n",
    "test_loader = DataLoader(tensor_dataset_test,batch_size=128) # for debug set num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model =ECG.EmotionRec()\n",
    "# training\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 100)\n",
    "torch.save(model.state_dict(), './model_light_100.pt')\n",
    "trainer.fit(model, train_loader,test_loader)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 150)\n",
    "torch.save(model.state_dict(), './model_light_250.pt')\n",
    "trainer.fit(model, train_loader,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0aa929e48ae0db39a69dcbd37837ab595187f0cb1d504a00a5afd7a7172afefd2"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "906877fa3b0a2f49e197f8df9a8e615c458bb20b42717d7901a87c548a873a9a"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
