{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-02 21:58:58.594212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 21:59:04.213466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-02 21:59:04.213839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-02 21:59:04.213851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<module 'ECG' from '../ECG.py'>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# done cause every time I change data_preprocessing.py it didn't affect\n",
    "import importlib\n",
    "\n",
    "# import outsiders\n",
    "sys.path.append('..')\n",
    "import data_preprocessing\n",
    "import ECG\n",
    "importlib.reload(data_preprocessing)\n",
    "importlib.reload(ECG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_data = data_preprocessing.load_data(os.path.join(\"../swell_dataset\",\"swell_dict_index_6.npy\"))\n",
    "swell_data = data_preprocessing.swell_prepare_for_10fold(swell_data)\n",
    "before=copy.copy(swell_data)\n",
    "#fix the range of the labels to init from value of zero\n",
    "swell_data[:,1:4]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot len is  14595\n",
      "trin len is  13135.5\n",
      "test len is  1459.5\n",
      "train obj:\n",
      "test obj:\n",
      "{2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0} 12567\n",
      "{1.0, 18.0, 25.0} 2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "def train_test_indexes_var2(ratio, objects):\n",
    "    # Split objects into train and test sets\n",
    "    num_test = int(len(set(objects)))-int(len(set(objects)) * ratio)\n",
    "    obj_list = list(set(objects))\n",
    "    random.shuffle(obj_list)\n",
    "    test_objs = obj_list[:num_test]\n",
    "    train_objs = obj_list[num_test:]\n",
    "\n",
    "    train_idxs = []\n",
    "    test_idxs = []\n",
    "\n",
    "    # Assign each object's samples to the appropriate set\n",
    "    for obj in train_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        train_idxs.extend(obj_idxs)\n",
    "\n",
    "    for obj in test_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        test_idxs.extend(obj_idxs)\n",
    "\n",
    "    # Shuffle the final train and test sets\n",
    "    random.shuffle(train_idxs)\n",
    "    random.shuffle(test_idxs)\n",
    "\n",
    "    return (train_idxs), (test_idxs)\n",
    "# check train_test_indexes_var2()\n",
    "# not for each runnig acieve exaclty 9:1 train:test\n",
    "ratio = 0.9\n",
    "objects=swell_data[:,0]\n",
    "print(\"tot len is \", len(objects))\n",
    "print(\"trin len is \",ratio*len(objects))\n",
    "print(\"test len is \",len(objects)-ratio*len(objects))\n",
    "i=train_test_indexes_var2(ratio, objects)\n",
    "#print(\"train idx \",i[0])\n",
    "#print(\"test idx \",i[1])\n",
    "print(\"train obj:\")\n",
    "tr=[]\n",
    "for j in i[0]:\n",
    "  #print(objects[int(j)])\n",
    "  tr.append(objects[int(j)])\n",
    "tr_u=set(tr)\n",
    "\n",
    "print(\"test obj:\")\n",
    "te=[]\n",
    "for j in i[1]:\n",
    "  #print(objects[int(j)])\n",
    "  te.append(objects[int(j)])\n",
    "te_u=set(te)\n",
    "\n",
    "print(tr_u,len(tr))\n",
    "print(te_u,len(te))\n",
    "splits=i\n",
    "np.save(\"./splits_B\",splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr=[]\n",
    "y_tr=[]\n",
    "for i in splits[0]:\n",
    "    x_tr.append(swell_data[i,4:])\n",
    "    y_tr.append(swell_data[i,:4])\n",
    "x_train=np.array(x_tr)\n",
    "y_train=np.array(y_tr)\n",
    "\n",
    "x_te=[]\n",
    "y_te=[]\n",
    "for i in splits[1]:\n",
    "    x_te.append(swell_data[i,4:])\n",
    "    y_te.append(swell_data[i,:4])\n",
    "x_test=np.array(x_te)\n",
    "y_test=np.array(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "(x_train).shape\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float().unsqueeze(1)\n",
    "#y_train = torch.from_numpy(y_train).long()\n",
    "y_train = torch.tensor(y_train).long()\n",
    "x_test = torch.from_numpy(x_test).float().unsqueeze(1)\n",
    "#y_test = torch.from_numpy(y_test).long()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "tensor_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "tensor_dataset_test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "train_loader = DataLoader(tensor_dataset, batch_size=128) # for debug set num_workers=0\n",
    "test_loader = DataLoader(tensor_dataset_test,batch_size=128) # for debug set num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | cnn     | Sequential | 329 K \n",
      "1 | stress  | Sequential | 330 K \n",
      "2 | arousal | Sequential | 333 K \n",
      "3 | valence | Sequential | 333 K \n",
      "---------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.304     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 115/115 [00:03<00:00, 33.14it/s, loss=0.258, v_num=5, train_stress_acc=1.000, train_arousal_acc=1.000, train_valence_acc=1.000, test_loss_stress=3.320, test_acc_stress=0.449, test_loss_arousal=16.60, test_acc_arousal=0.0246, test_loss_valence=10.80, test_acc_valence=0.0355]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 115/115 [00:03<00:00, 31.64it/s, loss=0.258, v_num=5, train_stress_acc=1.000, train_arousal_acc=1.000, train_valence_acc=1.000, test_loss_stress=3.320, test_acc_stress=0.449, test_loss_arousal=16.60, test_acc_arousal=0.0246, test_loss_valence=10.80, test_acc_valence=0.0355]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | cnn     | Sequential | 329 K \n",
      "1 | stress  | Sequential | 330 K \n",
      "2 | arousal | Sequential | 333 K \n",
      "3 | valence | Sequential | 333 K \n",
      "---------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.304     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home1/eitan.c@staff.technion.ac.il/ECG_proj/dockvenv/code/venv/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 115/115 [00:03<00:00, 33.68it/s, loss=0.076, v_num=6, train_stress_acc=1.000, train_arousal_acc=1.000, train_valence_acc=1.000, test_loss_stress=5.200, test_acc_stress=0.401, test_loss_arousal=19.00, test_acc_arousal=0.0177, test_loss_valence=14.20, test_acc_valence=0.0538]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 115/115 [00:03<00:00, 32.14it/s, loss=0.076, v_num=6, train_stress_acc=1.000, train_arousal_acc=1.000, train_valence_acc=1.000, test_loss_stress=5.200, test_acc_stress=0.401, test_loss_arousal=19.00, test_acc_arousal=0.0177, test_loss_valence=14.20, test_acc_valence=0.0538]\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model =ECG.EmotionRec()\n",
    "# training\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 100)\n",
    "torch.save(model.state_dict(), './model_light_100_B.pt')\n",
    "trainer.fit(model, train_loader,test_loader)\n",
    "\n",
    "trainer = pl.Trainer(gpus = 1 , max_epochs = 150)\n",
    "torch.save(model.state_dict(), './model_light_250_B.pt')\n",
    "trainer.fit(model, train_loader,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0aa929e48ae0db39a69dcbd37837ab595187f0cb1d504a00a5afd7a7172afefd2"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "906877fa3b0a2f49e197f8df9a8e615c458bb20b42717d7901a87c548a873a9a"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}