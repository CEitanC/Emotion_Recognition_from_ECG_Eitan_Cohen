{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "from tsai.all import *\n",
    "import sklearn.metrics as skm\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import importlib\n",
    "\n",
    "# import outsiders\n",
    "sys.path.append('../pre_processing_and_recover_network/')\n",
    "import data_preprocessing\n",
    "importlib.reload(data_preprocessing)\n",
    "\n",
    "sys.path.append('../pytorch_model')\n",
    "import ECG\n",
    "importlib.reload(ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "def split_data_indexes(len_data, train_ratio):\n",
    "    indexes = list(range(len_data))\n",
    "    random.shuffle(indexes)\n",
    "    train_size = int(len_data * train_ratio)\n",
    "    train_indexes = indexes[:train_size]\n",
    "    test_indexes = indexes[train_size:]\n",
    "    return (train_indexes, test_indexes)\n",
    "# ssh remote\n",
    "swell_data = data_preprocessing.load_data(os.path.join(\"../pre_processing_and_recover_network/swell_dataset/\",\"swell_dict.npy\"))\n",
    "swell_data = data_preprocessing.swell_prepare_for_10fold(swell_data)\n",
    "swell_data[:, 1:4] -= 1\n",
    "x = swell_data[:, 4:]\n",
    "\n",
    "y_arousal = swell_data[:, 2]\n",
    "y_arousal = y_arousal.reshape(y_arousal.shape[0],)\n",
    "\n",
    "y_valence = swell_data[:, 3]\n",
    "y_valence = y_valence.reshape(y_valence.shape[0],)\n",
    "\n",
    "y_stress = swell_data[:, 1]\n",
    "y_stress = y_stress.reshape(y_stress.shape[0],)\n",
    "\n",
    "print(x.shape)\n",
    "print(type(x))\n",
    "print(y_stress.shape)\n",
    "print(y_valence.shape)\n",
    "print(y_arousal.shape)\n",
    "\n",
    "\n",
    "# set X to 3-Dim array\n",
    "x = np.array(x)\n",
    "x = np.expand_dims(x, axis=1)\n",
    "print(x.shape)\n",
    "filename = 'X_memmap.npy'\n",
    "X = np.memmap(filename, dtype='float32', mode='w+', shape=x.shape)\n",
    "X[:] = x[:]\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "\n",
    "filename = 'Y_arousal_memmap.npy'\n",
    "Y_arousal = np.memmap(filename, dtype='float32', mode='w+', shape=y_arousal.shape)\n",
    "Y_arousal[:] = y_arousal[:]\n",
    "\n",
    "filename = 'Y_valence_memmap.npy'\n",
    "Y_valence = np.memmap(filename, dtype='float32', mode='w+', shape=y_valence.shape)\n",
    "Y_valence[:] = y_valence[:]\n",
    "\n",
    "filename = 'Y_stress_memmap.npy'\n",
    "Y_stress = np.memmap(filename, dtype='float32', mode='w+', shape=y_stress.shape)\n",
    "Y_stress[:] = y_stress[:]\n",
    "print(Y_stress.shape)\n",
    "print(type(Y_stress))\n",
    "splits=split_data_indexes(X.shape[0],0.9)\n",
    "print(len(splits[0]))\n",
    "print(len(splits[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For randomal splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=np.load('./splits_A.npy',allow_pickle=True)\n",
    "path='./model_light_250.pt'\n",
    "path='./model_light_250_B.pt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For spliting subjests for Train and Test**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splits=np.load('./splits_B.npy',allow_pickle=True)\n",
    "path='./model_light_250_B.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14595, 128, 1])\n"
     ]
    }
   ],
   "source": [
    "model_recovered=ECG.EmotionRec()\n",
    "model_recovered.load_state_dict(torch.load(path))\n",
    "model_recovered.eval()\n",
    "CNN=model_recovered.cnn\n",
    "tmp=swell_data[:, 4:]\n",
    "input=torch.from_numpy(tmp).float().unsqueeze(1)\n",
    "out=CNN.forward(input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14595, 128, 1)\n",
      "(14595, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "out2=out.detach().numpy()\n",
    "print((out2).shape)\n",
    "out3=np.transpose(out2,(0,2,1))\n",
    "print(out3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14595, 1, 128)\n",
      "<class 'numpy.memmap'>\n"
     ]
    }
   ],
   "source": [
    "filename = 'X_memmap.npy'\n",
    "X = np.memmap(filename, dtype='float32', mode='w+', shape=out3.shape)\n",
    "X[:] = out3[:]\n",
    "print(X.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare dataset loaders and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/S0.pth')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splits=split_data_indexes(X.shape[0],0.9) for using local\n",
    "splits=(splits[0],splits[1])\n",
    "\n",
    "dsets_arousal = TSDatasets(X, Y_arousal, tfms=[None, [Categorize()]], splits=splits, inplace=True)\n",
    "dsets_valence = TSDatasets(X, Y_valence, tfms=[None, [Categorize()]], splits=splits, inplace=True)\n",
    "dsets_stress = TSDatasets(X, Y_stress, tfms=[None, [Categorize()]], splits=splits, inplace=True)\n",
    "\n",
    "bs=128\n",
    "dls_stress = TSDataLoaders.from_dsets(dsets_stress.train, dsets_stress.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "dls_arousal = TSDataLoaders.from_dsets(dsets_arousal.train, dsets_arousal.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "dls_valence = TSDataLoaders.from_dsets(dsets_valence.train, dsets_valence.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "\n",
    "c_in=1\n",
    "c_out_stress=3\n",
    "c_out_arousal=9\n",
    "c_out_valence=9\n",
    "seq_len=128\n",
    "n_heads=4\n",
    "n_layers=4\n",
    "act='relu'\n",
    "max_seq_len=None\n",
    "d_model=32\n",
    "fc_dropout=0.1\n",
    "d_ff=32\n",
    "d_v=32\n",
    "d_k=32\n",
    "conv={\"kernel_size\":30,\"stride\":1}\n",
    "\n",
    "model_stress = TST(c_in=c_in, c_out=c_out_stress, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "model_arousal = TST(c_in=c_in, c_out=c_out_arousal, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "model_valence = TST(c_in=c_in, c_out=c_out_valence, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "\n",
    "learn_stress = Learner(dls_stress, model_stress, metrics=accuracy)\n",
    "learn_arousal = Learner(dls_arousal, model_arousal, metrics=accuracy)\n",
    "learn_valence = Learner(dls_valence, model_valence, metrics=accuracy)\n",
    "\n",
    "learn_stress.save('S-0')\n",
    "learn_arousal.save('S0')\n",
    "learn_valence.save('S0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_stress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train for stress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0005754399462603033)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "learn_stress.load('S-0')\n",
    "learn_stress.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_stress.load('S-0')\n",
    "learn_stress.fit_one_cycle(100,lr_max=1e-3)\n",
    "learn_stress.save('S-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_stress.save_all(path='./TST_params/Stress', dls_fname='dls_stress', model_fname='model_stress', learner_fname='learner_stress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train for arousal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.00015848931798245758)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_arousal.load('S0')\n",
    "learn_arousal.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_arousal.load('S0')\n",
    "learn_arousal.fit_one_cycle(100,lr_max=1e-4)\n",
    "learn_arousal.save('S1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_arousal.save_all(path='./TST_params/Arousal', dls_fname='dls_arousal', model_fname='model_arousal', learner_fname='learner_arousal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train for valence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.00015848931798245758)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_valence.load('S0')\n",
    "learn_valence.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_valence.fit_one_cycle(100,lr_max=1e-4)\n",
    "learn_valence.save('S1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_valence.save_all(path='./TST_params/Valence', dls_fname='dls_valence', model_fname='model_valence', learner_fname='learner_valence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./TST_params/splits_TST_2504',splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**not same objcets in train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_indexes_var2(ratio, objects):\n",
    "    # Split objects into train and test sets\n",
    "    num_test = int(len(set(objects)))-int(len(set(objects)) * ratio)\n",
    "    obj_list = list(set(objects))\n",
    "    random.shuffle(obj_list)\n",
    "    test_objs = obj_list[:num_test]\n",
    "    train_objs = obj_list[num_test:]\n",
    "\n",
    "    train_idxs = []\n",
    "    test_idxs = []\n",
    "\n",
    "    # Assign each object's samples to the appropriate set\n",
    "    for obj in train_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        train_idxs.extend(obj_idxs)\n",
    "\n",
    "    for obj in test_objs:\n",
    "        obj_idxs = [i for i, o in enumerate(objects) if o == obj]\n",
    "        test_idxs.extend(obj_idxs)\n",
    "\n",
    "    # Shuffle the final train and test sets\n",
    "    random.shuffle(train_idxs)\n",
    "    random.shuffle(test_idxs)\n",
    "\n",
    "    return (train_idxs), (test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot len is  14595\n",
      "trin len is  13135.5\n",
      "test len is  1459.5\n",
      "train obj:\n",
      "test obj:\n",
      "{1.0, 2.0, 3.0, 4.0, 6.0, 7.0, 9.0, 10.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0} 12656\n",
      "{25.0, 12.0, 5.0} 1939\n"
     ]
    }
   ],
   "source": [
    "# check train_test_indexes_var2()\n",
    "# not for each runnig acieve exaclty 9:1 train:test\n",
    "ratio = 0.9\n",
    "objects=swell_data[:,0]\n",
    "print(\"tot len is \", len(objects))\n",
    "print(\"trin len is \",ratio*len(objects))\n",
    "print(\"test len is \",len(objects)-ratio*len(objects))\n",
    "i=train_test_indexes_var2(ratio, objects)\n",
    "#print(\"train idx \",i[0])\n",
    "#print(\"test idx \",i[1])\n",
    "print(\"train obj:\")\n",
    "tr=[]\n",
    "for j in i[0]:\n",
    "  #print(objects[int(j)])\n",
    "  tr.append(objects[int(j)])\n",
    "tr_u=set(tr)\n",
    "\n",
    "print(\"test obj:\")\n",
    "te=[]\n",
    "for j in i[1]:\n",
    "  #print(objects[int(j)])\n",
    "  te.append(objects[int(j)])\n",
    "te_u=set(te)\n",
    "\n",
    "print(tr_u,len(tr))\n",
    "print(te_u,len(te))\n",
    "splits=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/S0.pth')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms  = [None, [Categorize()]]\n",
    "\n",
    "dsets_arousal = TSDatasets(X, Y_arousal, tfms=tfms, splits=splits, inplace=True)\n",
    "dsets_valence = TSDatasets(X, Y_valence, tfms=tfms, splits=splits, inplace=True)\n",
    "dsets_stress = TSDatasets(X, Y_stress, tfms=tfms, splits=splits, inplace=True)\n",
    "\n",
    "bs=128\n",
    "dls_stress = TSDataLoaders.from_dsets(dsets_stress.train, dsets_stress.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "dls_arousal = TSDataLoaders.from_dsets(dsets_arousal.train, dsets_arousal.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "dls_valence = TSDataLoaders.from_dsets(dsets_valence.train, dsets_valence.valid, bs=bs, batch_tfms=[TSStandardize()], num_workers=0)\n",
    "\n",
    "c_in=1\n",
    "c_out_stress=3\n",
    "c_out_arousal=9\n",
    "c_out_valence=9\n",
    "seq_len=128\n",
    "n_heads=4\n",
    "n_layers=4\n",
    "act='relu'\n",
    "max_seq_len=None\n",
    "d_model=32\n",
    "fc_dropout=0.1\n",
    "d_ff=32\n",
    "d_v=32\n",
    "d_k=32\n",
    "conv={\"kernel_size\":30,\"stride\":1}\n",
    "\n",
    "model_stress = TST(c_in=c_in, c_out=c_out_stress, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "model_arousal = TST(c_in=c_in, c_out=c_out_arousal, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "model_valence = TST(c_in=c_in, c_out=c_out_valence, seq_len=seq_len, n_heads=n_heads, n_layers=n_layers,act=act,\n",
    "    max_seq_len=max_seq_len,d_model=d_model,fc_dropout=fc_dropout,d_ff=d_ff,d_v=d_v,d_k=d_k)\n",
    "\n",
    "learn_stress = Learner(dls_stress, model_stress, metrics=accuracy)\n",
    "learn_arousal = Learner(dls_arousal, model_arousal, metrics=accuracy)\n",
    "learn_valence = Learner(dls_valence, model_valence, metrics=accuracy)\n",
    "\n",
    "learn_stress.save('S-0')\n",
    "learn_arousal.save('S0')\n",
    "learn_valence.save('S0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train for Stress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0002290867705596611)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "learn_stress.load('S-0')\n",
    "learn_stress.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.093876</td>\n",
       "      <td>0.955346</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>0.928190</td>\n",
       "      <td>0.689531</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.045704</td>\n",
       "      <td>0.903355</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.029113</td>\n",
       "      <td>0.899999</td>\n",
       "      <td>0.680763</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.009356</td>\n",
       "      <td>0.879660</td>\n",
       "      <td>0.654977</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.989800</td>\n",
       "      <td>0.869397</td>\n",
       "      <td>0.594636</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.965325</td>\n",
       "      <td>0.882246</td>\n",
       "      <td>0.562145</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.931627</td>\n",
       "      <td>0.884251</td>\n",
       "      <td>0.511604</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.901143</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.478597</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.862510</td>\n",
       "      <td>0.927644</td>\n",
       "      <td>0.484270</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.830150</td>\n",
       "      <td>0.969911</td>\n",
       "      <td>0.489943</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.798808</td>\n",
       "      <td>1.043754</td>\n",
       "      <td>0.466735</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.765649</td>\n",
       "      <td>1.030384</td>\n",
       "      <td>0.486333</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.730520</td>\n",
       "      <td>1.096292</td>\n",
       "      <td>0.450232</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.699571</td>\n",
       "      <td>1.147741</td>\n",
       "      <td>0.453326</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.669070</td>\n",
       "      <td>1.154521</td>\n",
       "      <td>0.454358</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.633313</td>\n",
       "      <td>1.171364</td>\n",
       "      <td>0.447653</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.603064</td>\n",
       "      <td>1.199258</td>\n",
       "      <td>0.453842</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.572707</td>\n",
       "      <td>1.102626</td>\n",
       "      <td>0.461578</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.543904</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>0.493553</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.519638</td>\n",
       "      <td>1.154493</td>\n",
       "      <td>0.457968</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.501171</td>\n",
       "      <td>1.042132</td>\n",
       "      <td>0.537390</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.482039</td>\n",
       "      <td>1.110059</td>\n",
       "      <td>0.507994</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.474439</td>\n",
       "      <td>1.145948</td>\n",
       "      <td>0.512635</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.454505</td>\n",
       "      <td>1.115285</td>\n",
       "      <td>0.525013</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.448240</td>\n",
       "      <td>1.051259</td>\n",
       "      <td>0.521403</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.434973</td>\n",
       "      <td>1.045493</td>\n",
       "      <td>0.555441</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.427520</td>\n",
       "      <td>1.072464</td>\n",
       "      <td>0.558535</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.416085</td>\n",
       "      <td>1.080041</td>\n",
       "      <td>0.552347</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.406347</td>\n",
       "      <td>1.005162</td>\n",
       "      <td>0.578649</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.405854</td>\n",
       "      <td>1.022217</td>\n",
       "      <td>0.567818</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.400150</td>\n",
       "      <td>1.028426</td>\n",
       "      <td>0.566787</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>1.035706</td>\n",
       "      <td>0.548221</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.387766</td>\n",
       "      <td>0.981735</td>\n",
       "      <td>0.586385</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.387634</td>\n",
       "      <td>1.080101</td>\n",
       "      <td>0.565756</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.376022</td>\n",
       "      <td>1.045579</td>\n",
       "      <td>0.565240</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.380459</td>\n",
       "      <td>1.146177</td>\n",
       "      <td>0.556988</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.372622</td>\n",
       "      <td>1.067903</td>\n",
       "      <td>0.549252</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.365620</td>\n",
       "      <td>1.169006</td>\n",
       "      <td>0.535843</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.363468</td>\n",
       "      <td>1.091037</td>\n",
       "      <td>0.508510</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>1.144532</td>\n",
       "      <td>0.523981</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>1.150266</td>\n",
       "      <td>0.520371</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.355038</td>\n",
       "      <td>1.146330</td>\n",
       "      <td>0.531202</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.347259</td>\n",
       "      <td>1.159361</td>\n",
       "      <td>0.527592</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.344613</td>\n",
       "      <td>1.086696</td>\n",
       "      <td>0.542548</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.348839</td>\n",
       "      <td>1.177245</td>\n",
       "      <td>0.525013</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.342825</td>\n",
       "      <td>1.240137</td>\n",
       "      <td>0.519340</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.336738</td>\n",
       "      <td>1.228721</td>\n",
       "      <td>0.508510</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>1.236079</td>\n",
       "      <td>0.518824</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.333684</td>\n",
       "      <td>1.250265</td>\n",
       "      <td>0.519856</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.333876</td>\n",
       "      <td>1.209482</td>\n",
       "      <td>0.528107</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.330374</td>\n",
       "      <td>1.278789</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.327311</td>\n",
       "      <td>1.214965</td>\n",
       "      <td>0.510057</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.327302</td>\n",
       "      <td>1.181839</td>\n",
       "      <td>0.510572</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.327649</td>\n",
       "      <td>1.181030</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.328548</td>\n",
       "      <td>1.161390</td>\n",
       "      <td>0.530170</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.321430</td>\n",
       "      <td>1.290658</td>\n",
       "      <td>0.494069</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.316599</td>\n",
       "      <td>1.323673</td>\n",
       "      <td>0.496132</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.322338</td>\n",
       "      <td>1.251152</td>\n",
       "      <td>0.498711</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.323141</td>\n",
       "      <td>1.283339</td>\n",
       "      <td>0.497679</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.318427</td>\n",
       "      <td>1.342733</td>\n",
       "      <td>0.489428</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.311888</td>\n",
       "      <td>1.262509</td>\n",
       "      <td>0.507478</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.315319</td>\n",
       "      <td>1.265514</td>\n",
       "      <td>0.504899</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.316492</td>\n",
       "      <td>1.258434</td>\n",
       "      <td>0.498195</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.310330</td>\n",
       "      <td>1.251578</td>\n",
       "      <td>0.513151</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.306350</td>\n",
       "      <td>1.275078</td>\n",
       "      <td>0.498711</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.311113</td>\n",
       "      <td>1.273541</td>\n",
       "      <td>0.505931</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.310150</td>\n",
       "      <td>1.327370</td>\n",
       "      <td>0.495616</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.302963</td>\n",
       "      <td>1.250394</td>\n",
       "      <td>0.508510</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.310280</td>\n",
       "      <td>1.195731</td>\n",
       "      <td>0.520371</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.311570</td>\n",
       "      <td>1.208977</td>\n",
       "      <td>0.506447</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.309212</td>\n",
       "      <td>1.318243</td>\n",
       "      <td>0.486849</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.305813</td>\n",
       "      <td>1.312078</td>\n",
       "      <td>0.498711</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.301786</td>\n",
       "      <td>1.306825</td>\n",
       "      <td>0.496132</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.300642</td>\n",
       "      <td>1.327550</td>\n",
       "      <td>0.502321</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.304530</td>\n",
       "      <td>1.334410</td>\n",
       "      <td>0.489428</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.304792</td>\n",
       "      <td>1.312526</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.306514</td>\n",
       "      <td>1.344970</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.298344</td>\n",
       "      <td>1.305495</td>\n",
       "      <td>0.502321</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.298764</td>\n",
       "      <td>1.323007</td>\n",
       "      <td>0.491490</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.303946</td>\n",
       "      <td>1.306750</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.306076</td>\n",
       "      <td>1.311712</td>\n",
       "      <td>0.494585</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.300398</td>\n",
       "      <td>1.313508</td>\n",
       "      <td>0.503868</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.297998</td>\n",
       "      <td>1.284024</td>\n",
       "      <td>0.503352</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.299089</td>\n",
       "      <td>1.303622</td>\n",
       "      <td>0.500258</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.299566</td>\n",
       "      <td>1.320068</td>\n",
       "      <td>0.499226</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.303578</td>\n",
       "      <td>1.295270</td>\n",
       "      <td>0.500258</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.293079</td>\n",
       "      <td>1.311695</td>\n",
       "      <td>0.497679</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.296379</td>\n",
       "      <td>1.301937</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.291782</td>\n",
       "      <td>1.306755</td>\n",
       "      <td>0.498195</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.295730</td>\n",
       "      <td>1.301848</td>\n",
       "      <td>0.500774</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.296285</td>\n",
       "      <td>1.283761</td>\n",
       "      <td>0.504899</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.300939</td>\n",
       "      <td>1.295274</td>\n",
       "      <td>0.501289</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.307787</td>\n",
       "      <td>1.295439</td>\n",
       "      <td>0.504899</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.309001</td>\n",
       "      <td>1.293720</td>\n",
       "      <td>0.500774</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.301942</td>\n",
       "      <td>1.297373</td>\n",
       "      <td>0.500258</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.296719</td>\n",
       "      <td>1.295312</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.299332</td>\n",
       "      <td>1.289274</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.297466</td>\n",
       "      <td>1.290691</td>\n",
       "      <td>0.501805</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.300272</td>\n",
       "      <td>1.298385</td>\n",
       "      <td>0.502837</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Path('models/S-1.pth')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_stress.load('S-0')\n",
    "learn_stress.fit_one_cycle(100,lr_max=1e-4)\n",
    "learn_stress.save('S-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd0aa929e48ae0db39a69dcbd37837ab595187f0cb1d504a00a5afd7a7172afefd2"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "906877fa3b0a2f49e197f8df9a8e615c458bb20b42717d7901a87c548a873a9a"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
